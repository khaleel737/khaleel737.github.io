<!doctype html><html lang=en><head><script defer src=https://analytics.eu.umami.is/script.js data-website-id=ff740bb2-f741-4bc5-975e-49691d82ef39></script><meta charset=utf-8><meta name=generator content="Hugo 0.151.0"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta property="og:url" content="https://maxhalford.github.io/blog/ducklake-thoughts/"><link rel=canonical href=https://maxhalford.github.io/blog/ducklake-thoughts/><meta property="og:url" content="https://maxhalford.github.io/blog/ducklake-thoughts/"><meta property="og:site_name" content="Max Halford"><meta property="og:title" content="Thoughts on DuckLake"><meta property="og:description" content="DuckLake is the new data lake/warehouse from the makers of DuckDB. I really like the direction theyâ€™re taking. Iâ€™m hopeful it has the potential to streamline the data engineering workflow for many people, vastly reducing costs along the way.
Iâ€™m a bit of a nut and donâ€™t use SQLMesh or dbt. Instead, I built lea a few years ago, and we still use it at Carbonfact. I would probably pick SQLMesh if I had to start over, but lea allows me to explore new ideas, so Iâ€™m sticking to it for now."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-06-09T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-09T00:00:00+00:00"><meta property="article:tag" content="Data-Eng"><meta property="og:image" content="https://maxhalford.github.io/img/belle-ile.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://maxhalford.github.io/img/belle-ile.jpg"><meta name=twitter:title content="Thoughts on DuckLake"><meta name=twitter:description content="DuckLake is the new data lake/warehouse from the makers of DuckDB. I really like the direction theyâ€™re taking. Iâ€™m hopeful it has the potential to streamline the data engineering workflow for many people, vastly reducing costs along the way.
Iâ€™m a bit of a nut and donâ€™t use SQLMesh or dbt. Instead, I built lea a few years ago, and we still use it at Carbonfact. I would probably pick SQLMesh if I had to start over, but lea allows me to explore new ideas, so Iâ€™m sticking to it for now."><link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¦”</text></svg>"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maxhalford.github.io\/"},"articleSection":"blog","name":"Thoughts on DuckLake","headline":"Thoughts on DuckLake","description":"\u003cp\u003e\u003ca href=\u0022https:\/\/ducklake.select\/\u0022\u003eDuckLake\u003c\/a\u003e is the new data lake\/warehouse from the makers of DuckDB. I really like the direction they\u0026rsquo;re taking. I\u0026rsquo;m hopeful it has the potential to streamline the data engineering workflow for many people, vastly reducing costs along the way.\u003c\/p\u003e\n\u003cp\u003eI\u0026rsquo;m a bit of a nut and don\u0026rsquo;t use SQLMesh or dbt. Instead, I built \u003ca href=\u0022https:\/\/github.com\/carbonfact\/lea\u0022\u003elea\u003c\/a\u003e a few years ago, and we still use it at \u003ca href=\u0022https:\/\/carbonfact.org\u0022\u003eCarbonfact\u003c\/a\u003e. I would probably pick SQLMesh if I had to start over, but lea allows me to explore new ideas, so I\u0026rsquo;m sticking to it for now.\u003c\/p\u003e","inLanguage":"en-US","author":"","creator":"","publisher":"","accountablePerson":"","copyrightHolder":"","copyrightYear":"2025","datePublished":"2025-06-09 00:00:00 \u002b0000 UTC","dateModified":"2025-06-09 00:00:00 \u002b0000 UTC","url":"https:\/\/maxhalford.github.io\/blog\/ducklake-thoughts\/","keywords":["data-eng"]}</script><title>Thoughts on DuckLake â€¢ Max Halford</title><meta property="og:title" content="Thoughts on DuckLake â€¢ Max Halford"><meta property="og:type" content="article"><meta name=description content="DuckLake is the new data lake/warehouse from the makers of DuckDB. I really like the direction they&rsquo;re taking. I&rsquo;m hopeful it has the potential to streamline the data engineering workflow for many people, vastly reducing costs along the way.
I&rsquo;m a bit of a nut and don&rsquo;t use SQLMesh or dbt. Instead, I built lea a few years ago, and we still use it at Carbonfact. I would probably pick SQLMesh if I had to start over, but lea allows me to explore new ideas, so I&rsquo;m sticking to it for now."><link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css><link rel=stylesheet href=/css/github-markdown.min.css><link rel=stylesheet href=/css/highlight/github.css><link rel=stylesheet href=/css/index.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400;700&family=Permanent+Marker&display=swap" rel=stylesheet><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><article class=post id=article><div class="row center-xs" style=text-align:left><div class="col-xs-12 col-sm-10 col-md-7 col-lg-5"><div class=header><header class=header-parts><div class="signatures site-title"><a href=/>Max Halford ãƒ„</a></div><div class=header-links><a class=header-link href=/>Blog</a>
<a class=header-link href=/links/>Links</a>
<a class=header-link href=/bio/>Bio</a></div></header></div><header class=post-header><h1 class=post-title>Thoughts on DuckLake</h1><div class="row post-desc"><div class="col-xs-12 post-desc-items"><time class=posts-line-date datetime="2025-06-09 00:00:00 UTC">2025-06-09
</time><span class=posts-line-tag>data-eng</span></div></div></header><div class="post-content markdown-body"><p><a href=https://ducklake.select/>DuckLake</a> is the new data lake/warehouse from the makers of DuckDB. I really like the direction they&rsquo;re taking. I&rsquo;m hopeful it has the potential to streamline the data engineering workflow for many people, vastly reducing costs along the way.</p><p>I&rsquo;m a bit of a nut and don&rsquo;t use SQLMesh or dbt. Instead, I built <a href=https://github.com/carbonfact/lea>lea</a> a few years ago, and we still use it at <a href=https://carbonfact.org>Carbonfact</a>. I would probably pick SQLMesh if I had to start over, but lea allows me to explore new ideas, so I&rsquo;m sticking to it for now.</p><p>I just added support in lea for DuckLake, which wasn&rsquo;t too hard because DuckDB is already supported. Here&rsquo;s an example to run some analytical queries for another <a href=https://github.com/MaxHalford/bike-sharing-history>project</a> of mine:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>git clone https://github.com/MaxHalford/bike-sharing-history --depth <span class=m>1</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> bike-sharing-history
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;
</span></span></span><span class=line><span class=cl><span class=s2>LEA_WAREHOUSE=ducklake
</span></span></span><span class=line><span class=cl><span class=s2>LEA_DUCKLAKE_DATA_PATH=gcs://bike-sharing-analytics
</span></span></span><span class=line><span class=cl><span class=s2>LEA_DUCKLAKE_CATALOG_DATABASE=metadata.ducklake
</span></span></span><span class=line><span class=cl><span class=s2>LEA_DUCKLAKE_S3_ENDPOINT=storage.googleapis.com
</span></span></span><span class=line><span class=cl><span class=s2>&#34;</span> &gt; .env
</span></span><span class=line><span class=cl>uvx --from lea-cli lea run --scripts analytics
</span></span></code></pre></div><p><em>I do recommend <a href=https://docs.astral.sh/uv/guides/tools/>uvx</a></em></p><p>So what&rsquo;s the point of DuckLake? In my opinion, the technical details of how it handles metadata versus, say, Iceberg, are not that important. It might be the case that Iceberg doesn&rsquo;t cope well with many writes and small files, but that&rsquo;s <a href=https://www.theregister.com/2025/06/05/ducklake_db_industry_reacts/>already</a> being worked on. Most of the technical details go over my head anyway.</p><p>What excites me about DuckLake is that it can make DuckDB function as a data warehouse. DuckLake advertises key features like snapshotting, ACID transactions, and time travel, which are all great. But the most important feature is that it enables running DuckDB queries in a remote data lake, which is something that wasn&rsquo;t straightforward so far.</p><p>Hear me out. When you&rsquo;re running your dbt/SQLMesh/lea DAG with DuckDB:</p><ol><li>The queries need to be executed on a node.</li><li>The query outputs need to be stored on a disk.</li></ol><p>The &ldquo;problem&rdquo; with DuckDB is that everything happens locally. That&rsquo;s great for small projects, but it&rsquo;s going to kill your laptop for anything semi-serious. The advantage of using Snowflake/BigQuery is that compute and storage happen in the cloud, and your machine is just orchestrating the queries.</p><p>It can be ok to use your laptop to do the compute, especially for development. Today&rsquo;s personal machines are powerful. By my estimate, you have to spend ~$0.54/hour to get access to a cloud machine with the same specs as a 2024 MacBook Pro. But you don&rsquo;t want to be storing terabytes of intermediate results on your laptop.</p><p>When I write SQL queries as part of a DAG, my dream workflow is to:</p><ol><li>Clone the production database in the cloud.</li><li>Edit the SQL queries.</li><li>Run the queries from my laptop, with the compute happening in the cloud.</li><li>Have the query outputs stored in the cloud.</li><li>Q/A the results from my laptop.</li><li>Push the changes to GitHub once I&rsquo;m happy.</li><li>Have steps 3. and 4. run automatically in CI/CD.</li></ol><p>This is what I do with BigQuery at work. It&rsquo;s fine. The only problem is that local development costs money, which feels wrong. I would love to transpile my SQL queries to DuckDB and run them locally. But in order to do that, I would have to clone the production database to my laptop, where there isn&rsquo;t enough disk space.</p><p>DuckDB supports the S3 API. Meaning that the data can live in <code>.parquet</code> files in an S3/GCS/R2 bucket. So we could imagine running compute locally, and having the query outputs stored in the bucket. Alas, DuckDB&rsquo;s S3 <a href=https://duckdb.org/docs/stable/core_extensions/httpfs/s3api.html#writing>write</a> support is limited to copying a local table to S3. So you would need to write the query outputs locally, and then copy them to the bucket, which is not ideal.</p><p>This is why I like DuckLake. When you <code>ATTACH</code> to DuckLake, there&rsquo;s a <code>DATA_PATH</code> parameter with many <a href=https://ducklake.select/docs/stable/duckdb/usage/choosing_storage>storage options</a> to choose from. This provides a way to execute DuckDB queries locally, and have the outputs stored in the cloud. I assume the query output chunks are progressively written to <code>.parquet</code> files in the bucket.</p><p>DuckLake is also quite simple to set up. With these environment variables:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=nv>LEA_WAREHOUSE</span><span class=o>=</span>ducklake
</span></span><span class=line><span class=cl><span class=nv>LEA_DUCKLAKE_DATA_PATH</span><span class=o>=</span>gcs://bike-sharing-analytics
</span></span><span class=line><span class=cl><span class=nv>LEA_DUCKLAKE_CATALOG_DATABASE</span><span class=o>=</span>metadata.ducklake
</span></span><span class=line><span class=cl><span class=nv>LEA_DUCKLAKE_S3_ENDPOINT</span><span class=o>=</span>storage.googleapis.com
</span></span></code></pre></div><p>Under the hood, lea runs the following SQL commands to set up the DuckLake connection:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=n>ATTACH</span><span class=w> </span><span class=s1>&#39;ducklake:metadata.ducklake&#39;</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>my_ducklake</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>DATA_PATH</span><span class=w> </span><span class=s1>&#39;gcs://bike-sharing-analytics&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>USE</span><span class=w> </span><span class=n>my_ducklake</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SET</span><span class=w> </span><span class=n>s3_endpoint</span><span class=o>=</span><span class=s1>&#39;storage.googleapis.com&#39;</span><span class=w>
</span></span></span></code></pre></div><p>What about MotherDuck? Well, the truth is that the same setup can be achieved with MotherDuck. Here are the differences I see:</p><ul><li>With DuckLake the data lives in your bucket, and you don&rsquo;t need to use a third-party service &ndash; important for enterprise.</li><li>MotherDuck can handle compute for you, which is an advantage. In particular, I&rsquo;m not exactly sure how DuckLake is meant to be used from CI/CD pipelines, where you don&rsquo;t usually have access to a big machine.</li><li>MotherDuck <a href=https://motherduck.com/docs/concepts/architecture-and-capabilities/#considerations-and-limitations>doesn&rsquo;t</a> support all of DuckDB&rsquo;s features.</li><li>MotherDuck gives you access to a nice UI, but I&rsquo;m sure they&rsquo;ll add support for DuckLake soon.</li></ul><p><em>For the record, lea supports MotherDuck too:</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=nv>LEA_WAREHOUSE</span><span class=o>=</span>motherduck
</span></span><span class=line><span class=cl><span class=nv>MOTHERDUCK_TOKEN</span><span class=o>=</span>&lt;get this from https://app.motherduck.com/settings/tokens&gt;
</span></span><span class=line><span class=cl><span class=nv>LEA_MOTHERDUCK_DATABASE</span><span class=o>=</span>bike_sharing
</span></span></code></pre></div><p>To summarize, the next big thing I want to see is the ability to transpile BigQuery/Snowflake SQL queries to DuckDB, have them run locally (or not), and have the outputs stored in a blob storage bucket. DuckLake is a step in the right direction.</p></div><script type=text/javascript>var s=document.createElement("script");s.setAttribute("src","https://utteranc.es/client.js"),s.setAttribute("repo","MaxHalford/maxhalford.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",null),s.setAttribute("theme","github-light"),document.body.appendChild(s)</script><div style=display:flex;flex-direction:row;justify-content:center;align-items:center;gap:20px;margin-bottom:30px><div class=do-the-thing><div class=elevator><svg class="sweet-svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" enable-background="new 0 0 100 100" height="100" width="100"><path d="M70 47.5H30c-1.4.0-2.5 1.1-2.5 2.5v40c0 1.4 1.1 2.5 2.5 2.5h40c1.4.0 2.5-1.1 2.5-2.5V50C72.5 48.6 71.4 47.5 70 47.5zm-22.5 40h-5v-25h5v25zm10 0h-5v-25h5v25zm10 0h-5V60c0-1.4-1.1-2.5-2.5-2.5H40c-1.4.0-2.5 1.1-2.5 2.5v27.5h-5v-35h35v35z"/><path d="M50 42.5c1.4.0 2.5-1.1 2.5-2.5V16l5.7 5.7c.5.5 1.1.7 1.8.7s1.3-.2 1.8-.7c1-1 1-2.6.0-3.5l-10-10c-1-1-2.6-1-3.5.0l-10 10c-1 1-1 2.6.0 3.5 1 1 2.6 1 3.5.0l5.7-5.7v24c0 1.4 1.1 2.5 2.5 2.5z"/></svg>
Back to the top</div></div><div class=subscribe><a href=http://eepurl.com/iRBqMg>Subscribe</a></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/elevator.js/1.0.1/elevator.min.js></script><script>var elementButton=document.querySelector(".elevator"),elevator=new Elevator({element:elementButton,mainAudio:"/music/elevator.mp3",endAudio:"/music/ding.mp3"})</script><style>.down-arrow{font-size:120px;margin-top:90px;margin-bottom:90px;text-shadow:0 -20px #0c1f31,0 0 #c33329;color:transparent;-webkit-transform:scaleY(.8);-moz-transform:scaleY(.8);transform:scaleY(.8)}.elevator{text-align:center;cursor:pointer;width:140px;margin:auto}.elevator:hover{opacity:.7}.elevator svg{width:40px;height:40px;display:block;margin:auto;margin-bottom:5px}</style><div class=related-content><h3 style=margin-top:10px!important;margin-bottom:10px!important>Related posts</h3><ul style=margin-top:0><li><a href=/blog/efficient-data-transformation/>Efficient ELT refreshes</a></li><li><a href=/blog/grouping-sets/>Dashboards and GROUPING SETS</a></li><li><a href=/blog/dbt-ref-rant/>A rant against dbt ref</a></li></ul></div></div></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll("img"));images.forEach(e=>{mediumZoom(e,{margin:0,scrollOffset:40,container:null,template:null})})</script></body></html>