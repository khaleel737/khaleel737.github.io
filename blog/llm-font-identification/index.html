<!doctype html><html lang=en><head><script defer src=https://analytics.eu.umami.is/script.js data-website-id=ff740bb2-f741-4bc5-975e-49691d82ef39></script><meta charset=utf-8><meta name=generator content="Hugo 0.152.1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta property="og:url" content="https://maxhalford.github.io/blog/llm-font-identification/"><link rel=canonical href=https://maxhalford.github.io/blog/llm-font-identification/><meta property="og:url" content="https://maxhalford.github.io/blog/llm-font-identification/"><meta property="og:site_name" content="Max Halford"><meta property="og:title" content="Do LLMs identify fonts?"><meta property="og:description" content="Spoiler: not really
dafont.com is a wonderful website that contains a large collection of fonts. Itâ€™s more comprehensive and esoteric than Google Fonts. One of its features is a forum where users can ask for help identifying fonts â€“ check out this poor fellow whoâ€™s been waiting for over two years and bumped his thread. I thought it would be interesting to see if an LLM could do this task, so I scraped the forum and set up a benchmark."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-07-30T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-30T00:00:00+00:00"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Scraping"><meta property="og:image" content="https://maxhalford.github.io/img/belle-ile.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://maxhalford.github.io/img/belle-ile.jpg"><meta name=twitter:title content="Do LLMs identify fonts?"><meta name=twitter:description content="Spoiler: not really
dafont.com is a wonderful website that contains a large collection of fonts. Itâ€™s more comprehensive and esoteric than Google Fonts. One of its features is a forum where users can ask for help identifying fonts â€“ check out this poor fellow whoâ€™s been waiting for over two years and bumped his thread. I thought it would be interesting to see if an LLM could do this task, so I scraped the forum and set up a benchmark."><link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¦”</text></svg>"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maxhalford.github.io\/"},"articleSection":"blog","name":"Do LLMs identify fonts?","headline":"Do LLMs identify fonts?","description":"\u003cp\u003e\u003cem\u003eSpoiler: \u003ca href=\u0022https:\/\/maxhalford.github.io\/llm-font-recognition\/\u0022\u003enot really\u003c\/a\u003e\u003c\/em\u003e\u003c\/p\u003e\n\u003cp\u003e\u003ca href=\u0022https:\/\/www.dafont.com\/fr\/\u0022\u003edafont.com\u003c\/a\u003e is a wonderful website that contains a large collection of fonts. It\u0026rsquo;s more comprehensive and esoteric than Google Fonts. One of its features is a forum where users can ask for help identifying fonts \u0026ndash; check out \u003ca href=\u0022https:\/\/www.dafont.com\/forum\/read\/522670\/font-identification\u0022\u003ethis poor fellow\u003c\/a\u003e who\u0026rsquo;s been waiting for over two years and bumped his thread. I thought it would be interesting to see if an LLM could do this task, so I scraped the forum and set up a benchmark.\u003c\/p\u003e","inLanguage":"en-US","author":"","creator":"","publisher":"","accountablePerson":"","copyrightHolder":"","copyrightYear":"2025","datePublished":"2025-07-30 00:00:00 \u002b0000 UTC","dateModified":"2025-07-30 00:00:00 \u002b0000 UTC","url":"https:\/\/maxhalford.github.io\/blog\/llm-font-identification\/","keywords":["llm","scraping"]}</script><title>Do LLMs identify fonts? â€¢ Max Halford</title><meta property="og:title" content="Do LLMs identify fonts? â€¢ Max Halford"><meta property="og:type" content="article"><meta name=description content="Spoiler: not really
dafont.com is a wonderful website that contains a large collection of fonts. It&rsquo;s more comprehensive and esoteric than Google Fonts. One of its features is a forum where users can ask for help identifying fonts &ndash; check out this poor fellow who&rsquo;s been waiting for over two years and bumped his thread. I thought it would be interesting to see if an LLM could do this task, so I scraped the forum and set up a benchmark."><link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css><link rel=stylesheet href=/css/github-markdown.min.css><link rel=stylesheet href=/css/highlight/github.css><link rel=stylesheet href=/css/index.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400;700&family=Permanent+Marker&display=swap" rel=stylesheet><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><article class=post id=article><div class="row center-xs" style=text-align:left><div class="col-xs-12 col-sm-10 col-md-7 col-lg-5"><div class=header><header class=header-parts><div class="signatures site-title"><a href=/>Max Halford ãƒ„</a></div><div class=header-links><a class=header-link href=/>Blog</a>
<a class=header-link href=/links/>Links</a>
<a class=header-link href=/bio/>Bio</a></div></header></div><header class=post-header><h1 class=post-title>Do LLMs identify fonts?</h1><div class="row post-desc"><div class="col-xs-12 post-desc-items"><time class=posts-line-date datetime="2025-07-30 00:00:00 UTC">2025-07-30
</time><span class=posts-line-tag>llm</span>
<span class=posts-line-tag>scraping</span></div></div></header><div class="post-content markdown-body"><p><em>Spoiler: <a href=https://maxhalford.github.io/llm-font-recognition/>not really</a></em></p><p><a href=https://www.dafont.com/fr/>dafont.com</a> is a wonderful website that contains a large collection of fonts. It&rsquo;s more comprehensive and esoteric than Google Fonts. One of its features is a forum where users can ask for help identifying fonts &ndash; check out <a href=https://www.dafont.com/forum/read/522670/font-identification>this poor fellow</a> who&rsquo;s been waiting for over two years and bumped his thread. I thought it would be interesting to see if an LLM could do this task, so I scraped the forum and set up a benchmark.</p><p>I implemented this as a live benchmark. By this I mean that I only ask the LLMs to identify fonts that haven&rsquo;t yet been identified by the community. I evaluate the LLMs prediction by comparing it to the community&rsquo;s prediction, once the latter has been made. This way, I&rsquo;m sure that I&rsquo;m asking the LLM to work on images it has never seen before. Indeed, there are many examples of biased LLMs that are just too good at memorizing <a href=https://vlmsarebiased.github.io/>images</a> and <a href=https://arxiv.org/html/2412.03597v1>text</a>.</p><p>Benchmark contamination is a real issue in LLM evaluation, so I think it&rsquo;s important to set up benchmarks this way when possible. There have been some great suggestions in this direction, including <a href="https://openreview.net/forum?id=sKYHBTAxVa">LiveBench</a> and the <a href=https://www.kaggle.com/competitions/konwinski-prize>Konwinski Prize</a></p><p>I evaluated only two LLMs: <code>gpt-4o-mini</code> and <code>gemini-2.5-flash-preview-05-20</code>. Each LLM is provided with the image uploaded by the user, the title of the thread, and a description if there is one. Providing these last two pieces of context is important, because some images contain several fonts, and the title or description may help the LLM focus on the right one. Take for instance this Marmite image:</p><div align=center><figure style=width:90%;margin:0><img src=/img/blog/llm-font-identification/marmite.png style=box-shadow:none></figure></div><p>Here are a couple extra difficult cases:</p><div align=center><figure style=width:90%;margin:0><img src=/img/blog/llm-font-identification/taylor-swift.png style=box-shadow:none></figure></div><div align=center><figure style=width:90%;margin:0><img src=/img/blog/llm-font-identification/luka-cinta.png style=box-shadow:none></figure></div><p>Each LLM is allowed to make up to five guesses. This allows calculating the accuracy at different levels of leniency. The performance is thus measured with a top-$k$ accuracy metric, which considers the LLM&rsquo;s first $k$ guesses and checks if the correct font is among them. I ran this benchmark for a few weeks, and here are the results as of writing this recap:</p><div align=center><figure style=width:90%;margin:0><img src=/img/blog/llm-font-identification/results.png style=box-shadow:none></figure></div><p>I find these results quite abysmal. It&rsquo;s hard to tell whether this is because the task is too difficult, or because the LLMs is being fairly evaluated on images it&rsquo;s never seen before. Answering this question would require going deeper and evaluating the LLMs on old images which it may have already seen. Anyway, I&rsquo;m happy in a weird way to have found a classification task which LLMs are not good at (yet?). I think this is a good reminder that LLMs are not magic, and that they still have a long way to go before being able to solve all tasks.</p><h2 id=implementation-notes>Implementation notes</h2><p>There&rsquo;s a Python script for <a href=https://github.com/MaxHalford/llm-font-recognition/blob/main/scrape_dafont.py>scraping dafont.com</a>, and another one for <a href=https://github.com/MaxHalford/llm-font-recognition/blob/main/ask_llms.py>prompting</a> the LLMs. It&rsquo;s the first I picked <a href=https://docs.astral.sh/uv/>uv</a> and it was a great experience. There&rsquo;s a simple <a href=https://github.com/MaxHalford/llm-font-recognition/blob/main/.github/workflows/run.yml>GitHub Actions workflow</a> which runs every 3 hours. The LLM logic is written with <a href=https://github.com/simonw/llm>Simon Willison&rsquo;s llm</a> package, which is super straightforward. All the results are stored in JSON files, and the benchmark is made with <a href=https://github.com/observablehq/framework>Observable Framework</a>. I had been meaning to try it for a while, and I have to say it&rsquo;s nice to define a dashboard with source code instead of a GUI. The live benchmark is hosted with GitHub Pages <a href=https://maxhalford.github.io/llm-font-recognition/>here</a>.</p></div><script type=text/javascript>var s=document.createElement("script");s.setAttribute("src","https://utteranc.es/client.js"),s.setAttribute("repo","MaxHalford/maxhalford.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",null),s.setAttribute("theme","github-light"),document.body.appendChild(s)</script><div style=display:flex;flex-direction:row;justify-content:center;align-items:center;gap:20px;margin-bottom:30px><div class=do-the-thing><div class=elevator><svg class="sweet-svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" enable-background="new 0 0 100 100" height="100" width="100"><path d="M70 47.5H30c-1.4.0-2.5 1.1-2.5 2.5v40c0 1.4 1.1 2.5 2.5 2.5h40c1.4.0 2.5-1.1 2.5-2.5V50C72.5 48.6 71.4 47.5 70 47.5zm-22.5 40h-5v-25h5v25zm10 0h-5v-25h5v25zm10 0h-5V60c0-1.4-1.1-2.5-2.5-2.5H40c-1.4.0-2.5 1.1-2.5 2.5v27.5h-5v-35h35v35z"/><path d="M50 42.5c1.4.0 2.5-1.1 2.5-2.5V16l5.7 5.7c.5.5 1.1.7 1.8.7s1.3-.2 1.8-.7c1-1 1-2.6.0-3.5l-10-10c-1-1-2.6-1-3.5.0l-10 10c-1 1-1 2.6.0 3.5 1 1 2.6 1 3.5.0l5.7-5.7v24c0 1.4 1.1 2.5 2.5 2.5z"/></svg>
Back to the top</div></div><div class=subscribe><a href=http://eepurl.com/iRBqMg>Subscribe</a></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/elevator.js/1.0.1/elevator.min.js></script><script>var elementButton=document.querySelector(".elevator"),elevator=new Elevator({element:elementButton,mainAudio:"/music/elevator.mp3",endAudio:"/music/ding.mp3"})</script><style>.down-arrow{font-size:120px;margin-top:90px;margin-bottom:90px;text-shadow:0 -20px #0c1f31,0 0 #c33329;color:transparent;-webkit-transform:scaleY(.8);-moz-transform:scaleY(.8);transform:scaleY(.8)}.elevator{text-align:center;cursor:pointer;width:140px;margin:auto}.elevator:hover{opacity:.7}.elevator svg{width:40px;height:40px;display:block;margin:auto;margin-bottom:5px}</style><div class=related-content><h3 style=margin-top:10px!important;margin-bottom:10px!important>Related posts</h3><ul style=margin-top:0><li><a href=/blog/declarative-web-scraping/>Web scraping, upside down</a></li><li><a href=/slides/manipulating-ephemeral-data-with-git.pdf>Manipulating ephemeral data with git</a></li></ul></div></div></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll("img"));images.forEach(e=>{mediumZoom(e,{margin:0,scrollOffset:40,container:null,template:null})})</script></body></html>