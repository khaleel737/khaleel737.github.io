<!doctype html><html lang=en><head><script defer src=https://analytics.eu.umami.is/script.js data-website-id=ff740bb2-f741-4bc5-975e-49691d82ef39></script><meta charset=utf-8><meta name=generator content="Hugo 0.144.2"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta property="og:url" content="https://maxhalford.github.io/blog/python-daily-cache/"><link rel=canonical href=https://maxhalford.github.io/blog/python-daily-cache/><meta property="og:url" content="https://maxhalford.github.io/blog/python-daily-cache/"><meta property="og:site_name" content="Max Halford"><meta property="og:title" content="@daily_cache implementation in Python"><meta property="og:description" content="I spend a lot of time at Carbonfact working on datasets shared by our customers. We typically set things up so that our customers can export data automatically. They usually deposit files to a GCP bucket, with a script, once a day. We then have an ETL script for each customer that runs afterwards to fetch their latest data and process it.
During development, I load customer data to my laptop and work on it. The datasets can be quite heavy, and it takes time to fetch them, so I cache them to save some time. Python has something for this in its standard library:"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-08-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-27T00:00:00+00:00"><meta property="article:tag" content="Python"><meta property="og:image" content="https://maxhalford.github.io/img/belle-ile.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://maxhalford.github.io/img/belle-ile.jpg"><meta name=twitter:title content="@daily_cache implementation in Python"><meta name=twitter:description content="I spend a lot of time at Carbonfact working on datasets shared by our customers. We typically set things up so that our customers can export data automatically. They usually deposit files to a GCP bucket, with a script, once a day. We then have an ETL script for each customer that runs afterwards to fetch their latest data and process it.
During development, I load customer data to my laptop and work on it. The datasets can be quite heavy, and it takes time to fetch them, so I cache them to save some time. Python has something for this in its standard library:"><link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¦†</text></svg>"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maxhalford.github.io\/"},"articleSection":"blog","name":"@daily_cache implementation in Python","headline":"@daily_cache implementation in Python","description":"\u003cp\u003eI spend a lot of time at Carbonfact working on datasets shared by our customers. We typically set things up so that our customers can export data automatically. They usually deposit files to a GCP bucket, with a script, once a day. We then have an ETL script for each customer that runs afterwards to fetch their latest data and process it.\u003c\/p\u003e\n\u003cp\u003eDuring development, I load customer data to my laptop and work on it. The datasets can be quite heavy, and it takes time to fetch them, so I cache them to save some time. Python has \u003ca href=\u0022https:\/\/docs.python.org\/3\/library\/functools.html\u0022\u003esomething\u003c\/a\u003e for this in its standard library:\u003c\/p\u003e","inLanguage":"en-US","author":"","creator":"","publisher":"","accountablePerson":"","copyrightHolder":"","copyrightYear":"2024","datePublished":"2024-08-27 00:00:00 \u002b0000 UTC","dateModified":"2024-08-27 00:00:00 \u002b0000 UTC","url":"https:\/\/maxhalford.github.io\/blog\/python-daily-cache\/","keywords":["python"]}</script><title>@daily_cache implementation in Python â€¢ Max Halford</title>
<meta property="og:title" content="@daily_cache implementation in Python â€¢ Max Halford"><meta property="og:type" content="article"><meta name=description content="I spend a lot of time at Carbonfact working on datasets shared by our customers. We typically set things up so that our customers can export data automatically. They usually deposit files to a GCP bucket, with a script, once a day. We then have an ETL script for each customer that runs afterwards to fetch their latest data and process it.
During development, I load customer data to my laptop and work on it. The datasets can be quite heavy, and it takes time to fetch them, so I cache them to save some time. Python has something for this in its standard library:"><link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css><link rel=stylesheet href=/css/github-markdown.min.css><link rel=stylesheet href=/css/highlight/github.css><link rel=stylesheet href=/css/index.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400;700&family=Permanent+Marker&display=swap" rel=stylesheet><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><article class=post id=article><div class="row center-xs" style=text-align:left><div class="col-xs-12 col-sm-10 col-md-7 col-lg-5"><div class=header><header class=header-parts><div class="signatures site-title"><a href=/>Max Halford ãƒ„</a></div><div class=header-links><a class=header-link href=/>Blog</a>
<a class=header-link href=/links/>Links</a>
<a class=header-link href=/bio/>Bio</a>
<a class=header-link href=/uses/>Uses</a></div></header></div><header class=post-header><h1 class=post-title>@daily_cache implementation in Python</h1><div class="row post-desc"><div class="col-xs-12 post-desc-items"><time class=posts-line-date datetime="2024-08-27 00:00:00 UTC">2024-08-27
</time><span class=posts-line-tag>python</span></div></div></header><div class="post-content markdown-body"><p>I spend a lot of time at Carbonfact working on datasets shared by our customers. We typically set things up so that our customers can export data automatically. They usually deposit files to a GCP bucket, with a script, once a day. We then have an ETL script for each customer that runs afterwards to fetch their latest data and process it.</p><p>During development, I load customer data to my laptop and work on it. The datasets can be quite heavy, and it takes time to fetch them, so I cache them to save some time. Python has <a href=https://docs.python.org/3/library/functools.html>something</a> for this in its standard library:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>import</span> <span class=nn>functools</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@functools.cache</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_raw_customer_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># Slow I/O...</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>process_customer_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>raw</span> <span class=o>=</span> <span class=n>raw_customer_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># Many operations, much compute, but it&#39;s fast...</span>
</span></span></code></pre></div><p>Under the hood, <code>@functools.cache</code> caches function outputs in RAM. The issue I have is that if I turn my computer off for lunch, then I lose the cache when I come back to it in the afternoon. Likewise if I reload my Jupyter notebook. But in fact, the cache is still valid because the customer hasn&rsquo;t uploaded any new data &ndash; because I know they do it once a day.</p><p>A simple solution is to use a cache that persists the data to disk. There is a Python package called joblib that <a href=https://joblib.readthedocs.io/en/latest/memory.html#memory>does this</a>. Here&rsquo;s an example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>memory</span> <span class=o>=</span> <span class=n>joblib</span><span class=o>.</span><span class=n>Memory</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>location</span><span class=o>=</span><span class=s1>&#39;~/customer_cache&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@memory.cache</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_raw_customer_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># Slow I/O...</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span></code></pre></div><p>The only issue with the snippet above is that the cache is never invalidated. There is actually a <a href=https://joblib.readthedocs.io/en/latest/memory.html#custom-cache-validation>documented way</a> to empty the cache after a certain amount of time, but that&rsquo;s not exactly what I want. I want to empty the cache once a day. For instance, if the last time I retrieved the data was yesterday, then I want to re-fetch it, even if it was only a few hours ago.</p><p>Thankfully, joblib allows you to pass a custom cache validation callback. You can provide a function, which takes as argument a metadata dictionary. One of the fields in this dictionary is called <code>time</code>, and represents the last moment when the function was called with a cache hit. We can therefore compare this field to the current date, and decide whether the cache should hit or miss. Here&rsquo;s how to do it:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>memory</span> <span class=o>=</span> <span class=n>joblib</span><span class=o>.</span><span class=n>Memory</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>location</span><span class=o>=</span><span class=s1>&#39;~/customer_cache&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>daily_cache_validation_callback</span><span class=p>(</span><span class=n>metadata</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>last_call_at</span> <span class=o>=</span> <span class=n>dt</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>fromtimestamp</span><span class=p>(</span><span class=n>metadata</span><span class=p>[</span><span class=s1>&#39;time&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>last_call_at</span><span class=o>.</span><span class=n>date</span><span class=p>()</span> <span class=o>==</span> <span class=n>dt</span><span class=o>.</span><span class=n>date</span><span class=o>.</span><span class=n>today</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>daily_cache</span> <span class=o>=</span> <span class=n>memory</span><span class=o>.</span><span class=n>cache</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>cache_validation_callback</span><span class=o>=</span><span class=n>daily_cache_validation_callback</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@daily_cache</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_raw_customer_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># Slow I/O...</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span></code></pre></div><p>It&rsquo;s quite straightforward to unit test the <code>@daily_cache</code> decorator thanks to the <a href=https://github.com/spulec/freezegun>FreezeGun</a> package:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>from</span> <span class=nn>freezegun</span> <span class=kn>import</span> <span class=n>freeze_time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Clear the cache for reproducibility</span>
</span></span><span class=line><span class=cl><span class=n>memory</span><span class=o>.</span><span class=n>clear</span><span class=p>(</span><span class=n>warn</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@daily_cache</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_raw_customer_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Loading data from scratch because it&#39;s </span><span class=si>{</span><span class=n>dt</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>freeze_time</span><span class=p>(</span><span class=s2>&#34;2024-08-27 09:00:00&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>load_raw_customer_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>freeze_time</span><span class=p>(</span><span class=s2>&#34;2024-08-27 15:00:00&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>load_raw_customer_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>freeze_time</span><span class=p>(</span><span class=s2>&#34;2024-08-28 06:00:00&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>load_raw_customer_data</span><span class=p>()</span>
</span></span></code></pre></div><pre tabindex=0><code>Loading data from scratch because it&#39;s 2024-08-27 09:00:00
Loading data from scratch because it&#39;s 2024-08-28 06:00:00
</code></pre><p>This is exactly what I needed. I hope it can be helpful to other people too.</p><p>There is however one last thing that isn&rsquo;t perfect with this solution. Sometimes, we notify customers that something is wrong in the data they shared, and occasionally they fix the issue and re-upload the data in the same day. In this case, the cache will still hit, and we will process the old data. It&rsquo;s a bit error-prone to have to clear the cache manually.</p><p>In an ideal world, I shouldn&rsquo;t have to assume files are refreshed every day, and the caching mechanism should figure out if something has changed or not. This usually by checking the last modification date of the remote file. This implies access to a file system, which can be tricky to abstract when your customers use a mix of AWS S3, GCP buckets, and other cloud storage solutions. The main advantage of the <code>@daily_cache</code> decorator above is that it agnostic of the data source, and so it works whatever file it is you are loading.</p><p>There is however a promising solution called <a href=https://filesystem-spec.readthedocs.io/en/latest/index.html>Filesystem Spec</a> (fsspec for short). It&rsquo;s a Python package that provides a common interface to many file systems, including cloud storage solutions. There is even <a href=https://filesystem-spec.readthedocs.io/en/latest/features.html#caching-files-locally>some documentation</a> on local caching. It isn&rsquo;t clear how to exactly set it up so that files are only re-downloaded when they change, but ChatGPT <a href=https://chatgpt.com/share/c6238444-99aa-4c77-972d-3f48b50fb942>figured it out</a>.</p></div><script type=text/javascript>var s=document.createElement("script");s.setAttribute("src","https://utteranc.es/client.js"),s.setAttribute("repo","MaxHalford/maxhalford.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",null),s.setAttribute("theme","github-light"),document.body.appendChild(s)</script><div style=display:flex;flex-direction:row;justify-content:center;align-items:center;gap:20px;margin-bottom:30px><div class=do-the-thing><div class=elevator><svg class="sweet-svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" enable-background="new 0 0 100 100" height="100" width="100"><path d="M70 47.5H30c-1.4.0-2.5 1.1-2.5 2.5v40c0 1.4 1.1 2.5 2.5 2.5h40c1.4.0 2.5-1.1 2.5-2.5V50C72.5 48.6 71.4 47.5 70 47.5zm-22.5 40h-5v-25h5v25zm10 0h-5v-25h5v25zm10 0h-5V60c0-1.4-1.1-2.5-2.5-2.5H40c-1.4.0-2.5 1.1-2.5 2.5v27.5h-5v-35h35v35z"/><path d="M50 42.5c1.4.0 2.5-1.1 2.5-2.5V16l5.7 5.7c.5.5 1.1.7 1.8.7s1.3-.2 1.8-.7c1-1 1-2.6.0-3.5l-10-10c-1-1-2.6-1-3.5.0l-10 10c-1 1-1 2.6.0 3.5 1 1 2.6 1 3.5.0l5.7-5.7v24c0 1.4 1.1 2.5 2.5 2.5z"/></svg>
Back to the top</div></div><div class=subscribe><a href=http://eepurl.com/iRBqMg>Subscribe</a></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/elevator.js/1.0.1/elevator.min.js></script><script>var elementButton=document.querySelector(".elevator"),elevator=new Elevator({element:elementButton,mainAudio:"/music/elevator.mp3",endAudio:"/music/ding.mp3"})</script><style>.down-arrow{font-size:120px;margin-top:90px;margin-bottom:90px;text-shadow:0 -20px #0c1f31,0 0 #c33329;color:transparent;-webkit-transform:scaleY(.8);-moz-transform:scaleY(.8);transform:scaleY(.8)}.elevator{text-align:center;cursor:pointer;width:140px;margin:auto}.elevator:hover{opacity:.7}.elevator svg{width:40px;height:40px;display:block;margin:auto;margin-bottom:5px}</style><div class=related-content><h3 style=margin-top:10px!important;margin-bottom:10px!important>Related posts</h3><ul style=margin-top:0><li><a href=/blog/lca-exit-the-matrix/>LCA software: exit the matrix</a></li><li><a href=/blog/carbon-footprint-pizzas/>Measuring the carbon footprint of pizzas</a></li><li><a href=/blog/weighted-sampling-without-replacement/>Weighted sampling without replacement in pure Python</a></li></ul></div></div></div></article></body></html>