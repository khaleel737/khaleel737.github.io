<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Analytics-Engineering on Max Halford</title><link>https://maxhalford.github.io/tags/analytics-engineering/</link><description>Recent content in Analytics-Engineering on Max Halford</description><generator>Hugo</generator><language>en-us</language><managingEditor>maxhalford25@gmail.com (Max Halford)</managingEditor><webMaster>maxhalford25@gmail.com (Max Halford)</webMaster><lastBuildDate>Sat, 08 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://maxhalford.github.io/tags/analytics-engineering/index.xml" rel="self" type="application/rss+xml"/><item><title>Minimizing the runtime of a SQL DAG</title><link>https://maxhalford.github.io/blog/minimizing-sql-dag-runtime/</link><pubDate>Sat, 08 Feb 2025 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/minimizing-sql-dag-runtime/</guid><description>&lt;p>I recently looked into reducing the runtime of &lt;a href="https://www.carbonfact.com/">Carbonfact&lt;/a>&amp;rsquo;s SQL DAG. Our DAG is made up of roughly 160 SQL queries. It takes roughly 10 minutes to run, using BigQuery &amp;ndash; with on-demand pricing. This is quite decent. However, the results of our DAG feed customer dashboards, and we have the (bad) habit of refreshing the DAG several times a day. Reducing the runtime by a few minutes can thus be a nice quality-of-life improvement.&lt;/p></description></item><item><title>Introducing icanexplain @ PyData Paris 2024</title><link>https://maxhalford.github.io/blog/icanexplain-pydata/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/icanexplain-pydata/</guid><description/></item></channel></rss>